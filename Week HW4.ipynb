{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "941a09f4",
   "metadata": {},
   "source": [
    "# Q1\n",
    "\n",
    "After watching the YouTube video, I learned that bootstrapping is a method used to estimate metrics like the average or variation in a dataset by creating many new samples from the original data. You take random samples with replacement, meaning you can put the data back and sample it again, which helps improve the accuracy of the results for the entire population. Additionally, the difference between the \"standard error of the mean\" and the \"standard deviation\" of the original data is that the population standard deviation (sigma) measures the dispersion of the original data, while the standard error of the mean reflects the dispersion of the simulated data in the bootstrap sample. The standard error of the mean also shows how reliable the sample mean is as a representation of the population mean, providing insight into the uncertainty or variability in the sample mean estimates.\n",
    "\n",
    "\n",
    "Summary:\n",
    "\n",
    "Bootstrapping:\n",
    "\n",
    "Bootstrapping is a resampling method used to estimate the distribution of a statistic by creating multiple samples from the original dataset. It helps in estimating measures like confidence intervals without strong assumptions about the population.\n",
    "The process involves creating \"bootstrap samples,\" calculating the desired statistic for each, and using these results to draw conclusions about the population.\n",
    "Difference Between Standard Error of the Mean (SEM) and Standard Deviation (SD):\n",
    "\n",
    "SD measures the variability of individual data points around the mean, representing the spread of the data itself.\n",
    "SEM measures how accurately the sample mean estimates the population mean, and it decreases as the sample size increases.\n",
    "While SD remains constant regardless of sample size, SEM reflects the precision of the sample mean and is influenced by sample size.\n",
    "\n",
    "Chatgpt link: https://chatgpt.com/share/66ff379c-a90c-8001-9eca-05166e179a41"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794df6d0",
   "metadata": {},
   "source": [
    "# Q2\n",
    "\n",
    "First, I collect multiple samples from the raw data and calculate the average of each sample. Then, I calculate the standard error of the bootstrapped means. Finally, I use the formula for the confidence interval to cover 95% of the samples. The formula is the sample mean ± (z * SEM), where z is the critical value of the z-score. These are the steps I follow when I want to determine a confidence interval.\n",
    "\n",
    "Summary:\n",
    "\n",
    "- **Calculate SEM**: \\(\\text{SEM} = \\frac{\\text{sample standard deviation}}{\\sqrt{n}}\\).\n",
    "- **Critical value for 95% confidence**: Use \\(z = 1.96\\).\n",
    "- **Confidence interval formula**: \\(\\text{CI} = \\text{sample mean} \\pm (1.96 \\times \\text{SEM})\\).\n",
    "- **Bootstrap context**: Calculate SEM from the standard deviation of bootstrapped sample means.\n",
    "- **Result**: 95% confidence interval covers 95% of bootstrapped sample means.\n",
    "\n",
    "Chatgpt link: https://chatgpt.com/share/66ff3992-13bc-8001-a2c2-7313f928225f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c8a4f3",
   "metadata": {},
   "source": [
    "# Q3\n",
    "\n",
    "To create a 95% bootstrapped confidence interval, first, use pd.read_csv(url) to import the sample data. Next, set the simulation parameters: reps, which is 1000, and sample_size, which is equal to the original sample size, \n",
    "n. Then, use np.zeros() to create some blank arrays. After that, use np.random.seed() to set the initial random values, ensuring the same result when the code is run again. Then, use np.random.choice() to sample the data (with replacement). Next, use sample.mean() to calculate the mean of each bootstrap sample. Finally, use np.quantile() to calculate the 2.5% and 97.5% quantiles from the 1000 bootstrap sample means to define the upper and lower limits of the confidence interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "201d9c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% Bootstrap Confidence Interval for the Median: [9.0, 13.0]\n"
     ]
    }
   ],
   "source": [
    "# Q4\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "sample = np.array([12, 7, 9, 15, 14, 11, 10, 8, 12, 9])\n",
    "\n",
    "n_bootstrap_samples = 1000\n",
    "\n",
    "confidence_level = 0.95\n",
    "\n",
    "def bootstrap_median(data, n_bootstrap_samples):\n",
    "    \"\"\"\n",
    "    Generate bootstrap samples and compute the median of each sample.\n",
    "    \"\"\"\n",
    " \n",
    "    medians = []\n",
    "\n",
    "    for _ in range(n_bootstrap_samples):\n",
    "       \n",
    "        bootstrap_sample = np.random.choice(data, size=len(data), replace=True)\n",
    "\n",
    "        sample_median = np.median(bootstrap_sample)\n",
    "\n",
    "        medians.append(sample_median)\n",
    "\n",
    "    return np.array(medians)\n",
    "\n",
    "bootstrap_medians = bootstrap_median(sample, n_bootstrap_samples)\n",
    "\n",
    "lower_bound = np.percentile(bootstrap_medians, (1 - confidence_level) / 2 * 100)\n",
    "upper_bound = np.percentile(bootstrap_medians, (1 + confidence_level) / 2 * 100)\n",
    "\n",
    "print(f\"95% Bootstrap Confidence Interval for the Median: [{lower_bound}, {upper_bound}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ead460",
   "metadata": {},
   "source": [
    "# Q4(summary)\n",
    "\n",
    "Bootstrap Confidence Interval for Population Median:\n",
    "Python code was provided to calculate a 95% bootstrap confidence interval for the population median using a sample. It works by generating multiple bootstrap samples (sampling with replacement from the original data) and computing the median for each.\n",
    "The confidence interval is calculated by taking the 2.5th and 97.5th percentiles of the bootstrap medians.\n",
    "The code also includes comments explaining how to modify it to compute confidence intervals for different population parameters, such as the mean or variance. You only need to change the statistic being computed (e.g., replace np.median() with np.mean() or np.var()).\n",
    "\n",
    "Chatgpt link: https://chatgpt.com/share/66ff5b3f-d2c8-8001-a6a4-cf8feefe36c9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12e3416",
   "metadata": {},
   "source": [
    "# Q5\n",
    "\n",
    "We need to distinguish between them because the population parameter is fixed but unknown. We use sample statistics to make predictions about it. However, we can't rely on just one sample because it is random, so we need to take multiple samples repeatedly to generate many sample statistics. This helps explain the interval within which the sample statistics are likely to fall. The more sample statistics we have, the greater the probability, and we can use values within this interval to predict the population parameter. Therefore, we use sample statistics to estimate the population parameter.\n",
    "\n",
    "Summmary:\n",
    "Population Parameter vs. Sample Statistic: The population parameter (e.g., population mean) is a fixed, unknown value describing the entire population, while the sample statistic (e.g., sample mean) is a calculated value from a subset of the population used to estimate the parameter. Confidence intervals are constructed around the sample statistic to estimate the population parameter, accounting for sampling error and variability. This distinction is key in interpreting the confidence interval, which gives a range of plausible values for the unknown population parameter.\n",
    "\n",
    "chatgpt link: https://chatgpt.com/share/66ff47d5-73fc-8001-b68b-697f8d479af1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499c9bfa",
   "metadata": {},
   "source": [
    "# Q6\n",
    "\n",
    "1. Bootstrapping is the process of repeatedly taking samples from an actual dataset (with replacement) to generate a series of new samples. Then, you calculate a statistic, like the average, for each sample. By doing this many times, you get a better estimate, even though you're using the same original data. It’s a way to test hypotheses using just one dataset.\n",
    "\n",
    "2. The purpose is to make a prediction about the population parameter using the statistics from these repeated samples. This helps to create confidence intervals and assess how stable or reliable a result is by simulating multiple possible samples from the original dataset.\n",
    "\n",
    "3. To test whether a hypothesized guess is plausible, we calculate the confidence interval from the bootstrapping results and check if the null hypothesis (H₀) falls within the interval. If it does, we fail to reject the null hypothesis; if it does not, we reject the null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4edbf52a",
   "metadata": {},
   "source": [
    "# Q7\n",
    "\n",
    "Fail to reject H0 because 95% situation that μ would between two values and this interval includes 0, which means μ can be zero under 95%. This means H0 is correct in this situation so we can't reject H0. It also means fail to reject H0. Because fail to ject H0 can't conclude Ha so we have no enough envidence to say that Ha is correct. Therefore, μ is not equals to zero, which means drug have no effects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68be2ce",
   "metadata": {},
   "source": [
    "# Q8\n",
    "\n",
    "H0: μd = 0 (vaccine has no effect)\n",
    "Ha: μd != 0 (vaccine has effect)\n",
    "From the CI of the code\n",
    "Because 0 is not between 0.9 and 5.5, so reject H0, conclude Ha. We have enough evidence to say that μd != 0, which means vaccine has effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35c48086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observed Mean: 3.3\n",
      "95% Confidence Interval: [0.9 5.5]\n"
     ]
    }
   ],
   "source": [
    "# Q8\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(1500)\n",
    "\n",
    "data = {\n",
    "    \"PatientID\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    \"InitialHealthScore\": [84, 78, 83, 81, 81, 80, 79, 85, 76, 83],\n",
    "    \"FinalHealthScore\": [86, 86, 80, 86, 84, 86, 86, 82, 83, 84]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df['HealthScoreChange'] = df['FinalHealthScore'] - df['InitialHealthScore']\n",
    "\n",
    "n_iterations = 10000\n",
    "boot_means = []\n",
    "observed_mean = df['HealthScoreChange'].mean()\n",
    "\n",
    "for i in range(n_iterations):\n",
    "    boot_sample = df['HealthScoreChange'].sample(frac=1, replace=True)\n",
    "    boot_means.append(boot_sample.mean())\n",
    "\n",
    "confidence_interval = np.percentile(boot_means, [2.5, 97.5])\n",
    "\n",
    "print(f\"Observed Mean: {observed_mean}\")\n",
    "print(f\"95% Confidence Interval: {confidence_interval}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6bbe60",
   "metadata": {},
   "source": [
    "# Q9\n",
    "Mostly. I've reviewed the course materials and interacted with ChatBot to help understand the tutorial and lecture content, but there are still some parts that I’m continuing to work on for deeper understanding."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
